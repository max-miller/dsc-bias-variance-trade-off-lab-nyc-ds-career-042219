{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-Variance Trade-Off - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge on the bias-variance trade-off!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to: \n",
    "- Look at an example where Polynomial regression leads to overfitting\n",
    "- Understand how bias-variance trade-off relates to underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll try to predict some movie revenues based on certain factors, such as ratings and movie year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>domgross</th>\n",
       "      <th>title</th>\n",
       "      <th>Response_Json</th>\n",
       "      <th>Year</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>imdbVotes</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13000000</td>\n",
       "      <td>25682380</td>\n",
       "      <td>21 &amp;amp; Over</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>6.8</td>\n",
       "      <td>48</td>\n",
       "      <td>206513</td>\n",
       "      <td>4.912759e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45658735</td>\n",
       "      <td>13414714</td>\n",
       "      <td>Dredd 3D</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.267265e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000000</td>\n",
       "      <td>53107035</td>\n",
       "      <td>12 Years a Slave</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.1</td>\n",
       "      <td>96</td>\n",
       "      <td>537525</td>\n",
       "      <td>1.626624e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61000000</td>\n",
       "      <td>75612460</td>\n",
       "      <td>2 Guns</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6.7</td>\n",
       "      <td>55</td>\n",
       "      <td>173726</td>\n",
       "      <td>7.723381e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40000000</td>\n",
       "      <td>95020213</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.5</td>\n",
       "      <td>62</td>\n",
       "      <td>74170</td>\n",
       "      <td>4.151958e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     budget  domgross             title  Response_Json  Year  imdbRating  \\\n",
       "0  13000000  25682380     21 &amp; Over              0  2008         6.8   \n",
       "1  45658735  13414714          Dredd 3D              0  2012         0.0   \n",
       "2  20000000  53107035  12 Years a Slave              0  2013         8.1   \n",
       "3  61000000  75612460            2 Guns              0  2013         6.7   \n",
       "4  40000000  95020213                42              0  2013         7.5   \n",
       "\n",
       "   Metascore  imdbVotes         Model  \n",
       "0         48     206513  4.912759e+07  \n",
       "1          0          0  2.267265e+05  \n",
       "2         96     537525  1.626624e+08  \n",
       "3         55     173726  7.723381e+07  \n",
       "4         62      74170  4.151958e+07  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_excel('./movie_data_detailed_with_ols.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domgross</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>imdbVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055325</td>\n",
       "      <td>0.034169</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.384192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023779</td>\n",
       "      <td>0.182956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125847</td>\n",
       "      <td>0.066059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183719</td>\n",
       "      <td>0.252847</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.323196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.233625</td>\n",
       "      <td>0.157175</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.137984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   domgross    budget  imdbRating  Metascore  imdbVotes\n",
       "0  0.055325  0.034169    0.839506   0.500000   0.384192\n",
       "1  0.023779  0.182956    0.000000   0.000000   0.000000\n",
       "2  0.125847  0.066059    1.000000   1.000000   1.000000\n",
       "3  0.183719  0.252847    0.827160   0.572917   0.323196\n",
       "4  0.233625  0.157175    0.925926   0.645833   0.137984"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep four predictors and transform the with MinMaxScaler\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "df = df[[ \"domgross\", \"budget\", \"imdbRating\", \"Metascore\", \"imdbVotes\"]]\n",
    "transformed = scale.fit_transform(df)\n",
    "pd_df = pd.DataFrame(transformed, columns = df.columns)\n",
    "pd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into a test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"budget\", \"imdbRating\", \"Metascore\", \"imdbVotes\"]], \n",
    "                                                    df['domgross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a regression model to the training data and look at the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.60409248e+00, 4.91794016e+06, 6.59242605e+05, 1.08887208e+02])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training predictions against the actual data (y_hat_train vs. y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our result for the train data. Because we have multiple predictors, we can not simply plot the income variable X on the x-axis and target y on the y-axis. Lets plot \n",
    "- A line showing the diagonal of y_train. The actual y_train values are on this line\n",
    "- Next, make a scatter plot that takes the actual y_train on the x-axis and the predictions using the model on the y-axis. You will see points scattered around the line. The horizontal distances between the points and the lines are the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5514f0ab00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# your code here\n",
    "y_hat_train = lm.predict(X_train)\n",
    "plt.scatter(y_hat_train, y_train)\n",
    "plt.plot(y_train,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the test predictions against the actual data (y_hat_test vs. y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the bias\n",
    "Create a function `bias` to calculate the bias of a models predictions given the actual data: $Bias(\\hat{f}(x)) = E[\\hat{f}(x)-f(x)]$   \n",
    "(The expected value can simply be taken as the mean or average value.)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def bias(y, y_hat):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the variance\n",
    "Create a function `variance` to calculate the variance of a model's predictions: $Var(\\hat{f}(x)) = E[\\hat{f}(x)^2] - \\big(E[\\hat{f}(x)]\\big)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(y_hat):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use your functions to calculate the bias and variance of your model. Do this separately for the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for train set bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for test set bias and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe in words what these numbers can tell you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your description here (this cell is formatted using markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit a new model by creating additional features by raising current features to various powers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `PolynomialFeatures` with degree 3. \n",
    "\n",
    "**Important note:** By including this, you don't only take polynomials of single variables, but you also combine variables, eg:\n",
    "\n",
    "$ \\text{Budget} * \\text{MetaScore} ^ 2 $\n",
    "\n",
    "What you're essentially doing is taking interactions and creating polynomials at the same time! Have a look at how many columns we get using `np.shape`. Quite a few!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\\\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot your overfitted model's training predictions against the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, we almost get a perfect fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the bias and variance for the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot your overfitted model's test predictions against the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Calculate the bias and variance for the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe what you notice about the bias and variance statistics for your overfit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your description here (this cell is formatted using markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we went from 4 predictors to 35 by adding polynomials and interactions, using `PolynomialFeatures`. That being said, where 35 leads to overfitting, there are probably ways to improve by just adding a few polynomials. Feel free to experiment and see how bias and variance improve!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab gave you insight into how bias and variance change for a training and a test set by using a pretty \"simple\" model, and a very complex model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
